{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project :: Evolution Strategies\n",
    "\n",
    "![img](https://t4.ftcdn.net/jpg/00/17/46/81/240_F_17468143_wY3hsHyfNYoMdG9BlC56HI4JA7pNu63h.jpg)\n",
    "\n",
    "Remember the idea behind Evolution Strategies? Here's a neat [blog post](https://blog.openai.com/evolution-strategies/) about 'em.\n",
    "\n",
    "Can you reproduce their success? You will have to implement evolutionary strategies and see how they work.\n",
    "\n",
    "This project is optional; has several milestones each worth a number of points [and swag].\n",
    "\n",
    "__Milestones:__\n",
    "* [10pts] Basic prototype of evolutionary strategies that works in one thread on CartPole\n",
    "* [+5pts] Modify the code to make them work in parallel\n",
    "* [+5pts] if you can run ES distributedly on at least two PCs\n",
    "* [+10pts] Apply ES to play Atari Pong at least better than random\n",
    "* [++] Additional points for all kinds of cool stuff besides milestones\n",
    "\n",
    "__Rules:__\n",
    "\n",
    "* This is __not a mandatory assignment__, but it's a way to learn some cool things if you're getting bored with default assignments.\n",
    "* Once you decided to take on this project, please tell any of course staff members so that we can help ypu if you get stuck.\n",
    "* There's a default implementation of ES in this [openai repo](https://github.com/openai/evolution-strategies-starter). It's okay to look there if you get stuck or want to compare your solutions, but each copy-pasted chunk of code should be understood thoroughly. We'll test that with questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips on implementation\n",
    "\n",
    "* It would be very convenient later if you implemented a function that takes policy weights, generates a session and returns policy changes -- so that you could then run a bunch of them in parallel.\n",
    "\n",
    "* The simplest way you can do multiprocessing is to use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
    "\n",
    "* For joblib, make sure random variables are independent in each job. Simply add `np.random.seed()` at the beginning of your \"job\" function.\n",
    "\n",
    "Later once you got distributed, you may need a storage that gathers gradients from all workers. In such case we recommend [Redis](https://redis.io/) due to it's simplicity.\n",
    "\n",
    "Here's a speed-optimized saver/loader to store numpy arrays in Redis as strings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from six import BytesIO\n",
    "def dumps(data):\n",
    "    \"\"\"converts whatever to string\"\"\"\n",
    "    s = BytesIO()\n",
    "    joblib.dump(data,s)\n",
    "    return s.getvalue()\n",
    "        \n",
    "def loads(self,string):\n",
    "    \"\"\"converts string to whatever was dumps'ed in it\"\"\"\n",
    "    return joblib.load(BytesIO(string))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips on atari games\n",
    "* There's all the pre-processing and tuning done for you in the code below\n",
    "    * Images rescaled to 42x42 to speed up computation\n",
    "    * We use last 4 frames as observations to account for ball velocity\n",
    "    * The code below requires ```pip install Image``` and ```pip install gym[atari]``` \n",
    "    * You may also need some dependencies for gym[atari] - google \"gym install all\" dependencies or use our pre-built environment.\n",
    "* The recommended agent architecture is a convolutional neural network. Dense network will also do.\n",
    "\n",
    "\n",
    "May the force be with you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <type 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Discrete(6)\n"
     ]
    }
   ],
   "source": [
    "from pong import make_pong\n",
    "import numpy as np\n",
    "\n",
    "env = make_pong()\n",
    "n_actions = env.action_space.n\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 42, 42)\n"
     ]
    }
   ],
   "source": [
    "#get the initial state\n",
    "s = env.reset()\n",
    "print (s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6c86d9f4d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#plot first observation. Only one frame\n",
    "plt.imshow(s.swapaxes(1,2).reshape(-1,s.shape[-1]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6c86d52390>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#next frame\n",
    "new_s,r,done, _ = env.step(env.action_space.sample())\n",
    "plt.imshow(new_s.swapaxes(1,2).reshape(-1,s.shape[-1]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6c86cc7890>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#after 10 frames\n",
    "for _ in range(10):\n",
    "    new_s,r,done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "plt.imshow(new_s.swapaxes(1,2).reshape(-1,s.shape[-1]).T,vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"solver = EvolutionStrategy()\n",
    "\n",
    "while True:\n",
    "\n",
    "  # ask the ES to give us a set of candidate solutions\n",
    "  solutions = solver.ask()\n",
    "\n",
    "  # create an array to hold the fitness results.\n",
    "  fitness_list = np.zeros(solver.popsize)\n",
    "\n",
    "  # evaluate the fitness for each given solution.\n",
    "  for i in range(solver.popsize):\n",
    "    fitness_list[i] = evaluate(solutions[i])\n",
    "\n",
    "  # give list of fitness results back to ES\n",
    "  solver.tell(fitness_list)\n",
    "\n",
    "  # get best parameter, fitness from ES\n",
    "  best_solution, best_fitness = solver.result()\n",
    "\n",
    "  if best_fitness > MY_REQUIRED_FITNESS:\n",
    "    break\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "agent = MLPClassifier(hidden_layer_sizes=(8,8),   # Weight matrix : (7056, 8) -> (8, 8) -> (8, 6)\n",
    "                      activation='tanh',\n",
    "                      warm_start=True, #keep progress between .fit(...) calls\n",
    "                      max_iter=1 #make only 1 iteration on each .fit(...)\n",
    "                     )\n",
    "#initialize agent to the dimension of state an amount of actions\n",
    "agent.fit([env.reset().flatten()] * n_actions, range(n_actions));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coefs():\n",
    "    layer_1_coef = np.random.rand(7056, 8)\n",
    "    layer_2_coef = np.random.rand(8, 8)\n",
    "    layer_3_coef = np.random.rand(8, 6)\n",
    "    \n",
    "    return [layer_1_coef, layer_2_coef, layer_3_coef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bias():\n",
    "    layer_1_bias = np.random.rand(8)\n",
    "    layer_2_bias = np.random.rand(8)\n",
    "    layer_3_bias = np.random.rand(6)\n",
    "    \n",
    "    return [layer_1_bias, layer_2_bias, layer_3_bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_generated = [generate_coefs() for _ in range(50)]\n",
    "bias_generated = [generate_bias() for _ in range(50)]\n",
    "index_solutions = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifierOverride(MLPClassifier):\n",
    "    def _initialize(self, y, layer_units):\n",
    "        # set all attributes, allocate weights etc for first call\n",
    "        # Initialize parameters\n",
    "        self.n_iter_ = 0\n",
    "        self.t_ = 0\n",
    "        self.n_outputs_ = y.shape[1]\n",
    "\n",
    "        # Compute the number of layers\n",
    "        self.n_layers_ = len(layer_units)\n",
    "\n",
    "        # Output for regression\n",
    "        if not is_classifier(self):\n",
    "            self.out_activation_ = 'identity'\n",
    "        # Output for multi class\n",
    "        elif self._label_binarizer.y_type_ == 'multiclass':\n",
    "            self.out_activation_ = 'softmax'\n",
    "        # Output for binary class and multi-label\n",
    "        else:\n",
    "            self.out_activation_ = 'logistic'\n",
    "\n",
    "        # Initialize coefficient and intercept layers\n",
    "        self.coefs_ = coefs_generated[index_solutions]\n",
    "        self.intercepts_ = bias_generated[index_solutions]\n",
    "\n",
    "        for i in range(self.n_layers_ - 1):\n",
    "            coef_init, intercept_init = self._init_coef(layer_units[i],\n",
    "                                                        layer_units[i + 1])\n",
    "            self.coefs_.append(coef_init)\n",
    "            self.intercepts_.append(intercept_init)\n",
    "\n",
    "        if self.solver in _STOCHASTIC_SOLVERS:\n",
    "            self.loss_curve_ = []\n",
    "            self._no_improvement_count = 0\n",
    "            if self.early_stopping:\n",
    "                self.validation_scores_ = []\n",
    "                self.best_validation_score_ = -np.inf\n",
    "            else:\n",
    "                self.best_loss_ = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(t_max = 100):\n",
    "    \"\"\"\n",
    "    plays a game and returns reward and parameters\n",
    "    \"\"\"\n",
    "    s = [env.reset().flatten()]\n",
    "    total_reward = 0\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        \n",
    "        #predict array of action probabilities\n",
    "        probs = agent.predict_proba(s)[0] \n",
    "        \n",
    "        a = np.random.choice(np.asarray(range(n_actions)), p=probs)#<sample action with such probabilities>\n",
    "        \n",
    "        new_s,r,done,info = env.step(a)\n",
    "        new_s = [new_s.flatten()]\n",
    "        #record sessions like you did before\n",
    "        total_reward+=r\n",
    "        \n",
    "        s = new_s\n",
    "        if done: break         \n",
    "    return total_reward, agent.coefs_, agent.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def select_best_n_solutions(samples_returned_number = 2, max_timesteps = 500):\n",
    "    \"\"\" 100 timesteps ~= reward between -1.5 and 1.5)\"\"\"\n",
    "    rewards_list = []\n",
    "    bias_list = []\n",
    "    coefs_list = []\n",
    "    maximas_list = []\n",
    "    returned_coefs = []\n",
    "    returned_bias = []\n",
    "    global index_solutions\n",
    "    \n",
    "    for i in bias_generated:\n",
    "        agent = MLPClassifier(hidden_layer_sizes=(8,8),   # Weight matrix : (7056, 8) -> (8, 8) -> (8, 6)\n",
    "                      activation='tanh',\n",
    "                      warm_start=True, #keep progress between .fit(...) calls\n",
    "                      max_iter=1 #make only 1 iteration on each .fit(...)\n",
    "                     )\n",
    "        \n",
    "        print (\"generating solution number \" + str(index_solutions))\n",
    "        agent.fit([env.reset().flatten()] * n_actions, range(n_actions));\n",
    "        index_solutions += 1\n",
    "        reward, coefs, bias = play_game(max_timesteps)\n",
    "        clear_output()\n",
    "        \n",
    "        rewards_list.append(reward)\n",
    "        coefs_list.append(coefs)\n",
    "        bias_list.append(bias)\n",
    "        print (\"rewards list : \" + str(rewards_list))\n",
    "    \n",
    "    for i in range(samples_returned_number):\n",
    "        maximum_index = rewards_list.index(max(rewards_list)) # getting the index of the best parameters\n",
    "        rewards_list.remove(max(rewards_list))                # removing the best parameter from the rewards_list\n",
    "        maximas_list.append(maximum_index)                   # maximums_list contains the index of the maximas\n",
    "    \n",
    "    for i in maximas_list:\n",
    "        returned_coefs.append(coefs_list[i])\n",
    "        returned_bias.append(bias_list[i])\n",
    "    \n",
    "    print (\"Maximum rewards'index : \" + str(maximas_list))\n",
    "    return returned_coefs, returned_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards list : [-10.0, -11.0, -10.0, -11.0, -13.0, -4.0, -11.0, -10.0, -10.0]\n",
      "generating solution number 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-5b65b171829f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbias_generated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_generation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mindex_solutions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcoefs_computed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_computed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_best_n_solutions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-172-94064c56be28>\u001b[0m in \u001b[0;36mselect_best_n_solutions\u001b[0;34m(samples_returned_number, max_timesteps)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"generating solution number \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_solutions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mindex_solutions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nbuser/Practical_RL/week1_intro/pong.pyc\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;34m\"\"\"resets breakout, returns initial frames\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframebuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframebuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframebuffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nbuser/.local/lib/python2.7/site-packages/gym/wrappers/time_limit.pyc\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/nbuser/.local/lib/python2.7/site-packages/gym/envs/atari/atari_env.pyc\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# return: (states, observations)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nbuser/.local/lib/python2.7/site-packages/atari_py/ale_python_interface.pyc\u001b[0m in \u001b[0;36mreset_game\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0male_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetLegalActionSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_generation = 50\n",
    "coefs_generated = [generate_coefs() for _ in range(max_generation)]\n",
    "bias_generated = [generate_bias() for _ in range(max_generation)]\n",
    "index_solutions = 0\n",
    "coefs_computed, bias_computed = select_best_n_solutions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
