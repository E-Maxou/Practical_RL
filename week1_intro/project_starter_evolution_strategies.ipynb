{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project :: Evolution Strategies\n",
    "\n",
    "![img](https://t4.ftcdn.net/jpg/00/17/46/81/240_F_17468143_wY3hsHyfNYoMdG9BlC56HI4JA7pNu63h.jpg)\n",
    "\n",
    "Remember the idea behind Evolution Strategies? Here's a neat [blog post](https://blog.openai.com/evolution-strategies/) about 'em.\n",
    "\n",
    "Can you reproduce their success? You will have to implement evolutionary strategies and see how they work.\n",
    "\n",
    "This project is optional; has several milestones each worth a number of points [and swag].\n",
    "\n",
    "__Milestones:__\n",
    "* [10pts] Basic prototype of evolutionary strategies that works in one thread on CartPole\n",
    "* [+5pts] Modify the code to make them work in parallel\n",
    "* [+5pts] if you can run ES distributedly on at least two PCs\n",
    "* [+10pts] Apply ES to play Atari Pong at least better than random\n",
    "* [++] Additional points for all kinds of cool stuff besides milestones\n",
    "\n",
    "__Rules:__\n",
    "\n",
    "* This is __not a mandatory assignment__, but it's a way to learn some cool things if you're getting bored with default assignments.\n",
    "* Once you decided to take on this project, please tell any of course staff members so that we can help ypu if you get stuck.\n",
    "* There's a default implementation of ES in this [openai repo](https://github.com/openai/evolution-strategies-starter). It's okay to look there if you get stuck or want to compare your solutions, but each copy-pasted chunk of code should be understood thoroughly. We'll test that with questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips on implementation\n",
    "\n",
    "* It would be very convenient later if you implemented a function that takes policy weights, generates a session and returns policy changes -- so that you could then run a bunch of them in parallel.\n",
    "\n",
    "* The simplest way you can do multiprocessing is to use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
    "\n",
    "* For joblib, make sure random variables are independent in each job. Simply add `np.random.seed()` at the beginning of your \"job\" function.\n",
    "\n",
    "Later once you got distributed, you may need a storage that gathers gradients from all workers. In such case we recommend [Redis](https://redis.io/) due to it's simplicity.\n",
    "\n",
    "Here's a speed-optimized saver/loader to store numpy arrays in Redis as strings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from six import BytesIO\n",
    "def dumps(data):\n",
    "    \"\"\"converts whatever to string\"\"\"\n",
    "    s = BytesIO()\n",
    "    joblib.dump(data,s)\n",
    "    return s.getvalue()\n",
    "        \n",
    "def loads(self,string):\n",
    "    \"\"\"converts string to whatever was dumps'ed in it\"\"\"\n",
    "    return joblib.load(BytesIO(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips on atari games\n",
    "* There's all the pre-processing and tuning done for you in the code below\n",
    "    * Images rescaled to 42x42 to speed up computation\n",
    "    * We use last 4 frames as observations to account for ball velocity\n",
    "    * The code below requires ```pip install Image``` and ```pip install gym[atari]``` \n",
    "    * You may also need some dependencies for gym[atari] - google \"gym install all\" dependencies or use our pre-built environment.\n",
    "* The recommended agent architecture is a convolutional neural network. Dense network will also do.\n",
    "\n",
    "\n",
    "May the force be with you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <type 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Discrete(6)\n"
     ]
    }
   ],
   "source": [
    "from pong import make_pong\n",
    "import numpy as np\n",
    "\n",
    "env = make_pong()\n",
    "n_actions = env.action_space.n\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 42, 42)\n"
     ]
    }
   ],
   "source": [
    "#get the initial state\n",
    "s = env.reset()\n",
    "print (s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb3ec4c4410>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 4 * 42 * 42\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb3ea372090>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#next frame\n",
    "new_s,r,done, _ = env.step(env.action_space.sample())\n",
    "plt.imshow(new_s.swapaxes(1,2).reshape(-1,s.shape[-1]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb3ea2e7550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB2CAYAAADY3GjsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAACodJREFUeJzt3X+s1XUdx/Hni/sDrqBwEYWrsMBCN/4wcZQ4qxmoETmxrRpqpctia+W0rAba2vovram1tYypjRVppKTM2ZiSa2stFPEXP0QxJWD8kK2AicMLvvvj+7l6ZPdyz73nx/fw4fXY7u75/jj3+9773O/rfO/n+z3fq4jAzMxOfCPKLsDMzOrDgW5mlgkHuplZJhzoZmaZcKCbmWXCgW5mlgkHuplZJmoKdEnzJG2RtFXS4noVZWZmQ6fhfrBIUhvwKnA5sAN4FrgmIjbVrzwzM6tWew3P/SSwNSL+DSDpIWABMGCgd47tilGTTqthk2ZmJ5+Dr+7dFxFnDLZeLYF+NrC9YnoHcNGxK0laBCwCGDXxVC6699oaNmlmdvJ5as4926pZr+EnRSNiaUTMiohZHWO7Gr05M7OTVi2BvhOYUjE9Oc0zM7MS1BLozwLTJU2T1AksBFbVpywzMxuqYY+hR8QRSd8FVgNtwAMRsbFulZmZ2ZDUclKUiHgCeKJOtZiZWQ38SVEzs0w40M3MMuFANzPLhAPdzCwTDnQzs0w40M3MMuFANzPLhAPdzCwTDnQzs0w40M3MMuFANzPLhAPdzCwTDnQzs0w40M3MMuFANzPLhAPdzCwTDnQzs0w40M3MMuFANzPLhAPdzCwTDnQzs0w40M3MMuFANzPLhAPdzCwTDnQzs0w40M3MMuFANzPLhAPdzCwTDnQzs0w40M3MMuFANzPLxKCBLmmKpKclbZK0UdLNaf54SU9Kei197258uWZmNpBqjtCPALdGxAxgNvAdSTOAxcCaiJgOrEnTZmZWkkEDPSJ2RcT69PggsBk4G1gALEurLQOublSRZmY2uCGNoUuaCswE1gITI2JXWrQbmDjAcxZJWidpXe/+d2oo1czMjqfqQJc0BngEuCUiDlQui4gAor/nRcTSiJgVEbM6xnbVVKyZmQ2sqkCX1EER5ssjYmWavUdST1reA+xtTIlmZlaNaq5yEXA/sDki7qpYtAq4Pj2+Hnis/uWZmVm12qtY5xLga8DLkl5I824DfgaskHQjsA34SmNKNDOzagwa6BHxD0ADLJ5b33LMzGy4/ElRM7NMONDNzDLhQDczy4QD3cwsEw50M7NMONDNzDLhQDczy4QD3cwsEw50M7NMONDNzDLhQDczy4QD3cwsEw50M7NMONDNzDLhQDczy4QD3cwsEw50M7NMVPMv6KxJOtqOAjCqrReAg++OKrMcMzvB+AjdzCwTPkJvIeeP3QnAt8b/E4Cb3vgyAL1H20qrycxOHD5CNzPLhI/QW8iYtsMATOsYA8AIRZnlmNkJxkfoZmaZcKCbmZWko+3o+1e31YMD3cwsEx5DbyG9UVzNcjTeK7kSM2uk87uLK9qu6/4XAD/edjVQ+xVtPkI3M8uEj9BbyMaDPQDc9l4nAO/6+vO6ULpaKEIlV2JW6G4/BMAFI0cC9buizUfoZmaZ8BF6C9l/uAuAFw5PLrmSPJw3dg8AC7rXA3D39isAf/LW8lX1EbqkNknPS3o8TU+TtFbSVkl/ktTZuDLNzGwwQxlyuRnYXDF9B3B3RHwM+C9wYz0LM6vVpM4DTOo8wNyuo8ztOsoIhT99O0xd7b10tfdy1uj9nDV6P1K8f27CWkdVgS5pMvAF4L40LWAO8HBaZRlwdSMKNDOz6lQ7hn4P8CPg1DR9OvC/iDiSpncAZ9e5NjNrETPHbQfg1tOL8xHXvl4cvx0+4tNww/HK2xMBuGtE8b8P6nVF26BH6JKuBPZGxHPD2YCkRZLWSVrXu/+d4fwIMzOrQjVvr5cAV0maD4wCTgN+CYyT1J6O0icDO/t7ckQsBZYCnHbeRA+6mZ2AOlTcb2TMCP8XrXrYc+g0AFYfmlHXnzvoEXpELImIyRExFVgI/C0irgOeBr6UVrseeKyulZmZ2ZAoovqDZkmXAj+IiCslnQM8BIwHnge+GhGHB3n+W8DbwL5hV9x4E3B9w9XKtYHrq5Xrq00t9X0kIs4YbKUhBXo9SFoXEbOautEhcH3D18q1geurleurTTPq80f/zcwy4UA3M8tEGYG+tIRtDoXrG75Wrg1cX61cX20aXl/Tx9DNzKwxPORiZpaJpgW6pHmStqS7My5u1naPU88USU9L2iRpo6Sb0/zxkp6U9Fr63l1ynS17l0tJ4yQ9LOkVSZslXdxK/ZP0vfTabpD0oKRRZfZP0gOS9kraUDGv336p8KtU50uSLiypvp+n1/clSX+RNK5i2ZJU3xZJnyujvoplt0oKSRPSdFP7N1Btkm5K/dso6c6K+Y3pXUQ0/AtoA14HzgE6gReBGc3Y9nFq6gEuTI9PBV4FZgB3AovT/MXAHSXX+X3gj8DjaXoFsDA9vhf4dom1LQO+mR53AuNapX8U9xZ6A+iq6NsNZfYP+AxwIbChYl6//QLmA38FBMwG1pZU3xVAe3p8R0V9M9J+PBKYlvbvtmbXl+ZPAVYD24AJZfRvgN59FngKGJmmz2x075r1i3wxsLpiegmwpBnbHkKNjwGXA1uAnjSvB9hSYk2TgTUUd7Z8PP1y7qvYwT7U1ybXNjYFpo6Z3xL9S4G+neKDb+2pf58ru3/A1GN2+n77BfwWuKa/9ZpZ3zHLvggsT48/tA+nQL24jPoo7vr6ceDNikBvev/6eW1XAJf1s17DetesIZe+natPS92dUdJUYCawFpgYEbvSot3AxJLKgg/ucvlemm6lu1xOA94CfpeGhO6TNJoW6V9E7AR+AfwH2AXsB56jdfrXZ6B+teI+8w2Ko15okfokLQB2RsSLxyxqhfrOBT6dhvj+LukTja7tpD8pKmkM8AhwS0QcqFwWxdtnKZcB1XqXyyZop/gT8zcRMZPilg4fOjdScv+6gQUUbzxnAaOBeWXUUq0y+zUYSbcDR4DlZdfSR9IpwG3AT8quZQDtFH8hzgZ+CKyQ1ND/VN6sQN9JMc7VZ8C7MzaTpA6KMF8eESvT7D2SetLyHmBvSeX13eXyTYp75syh4i6XaZ0y+7gD2BERa9P0wxQB3yr9uwx4IyLeioheYCVFT1ulf30G6lfL7DOSbgCuBK5LbzrQGvV9lOIN+8W0n0wG1kua1CL17QBWRuEZir+0JzSytmYF+rPA9HSFQSfFXRtXNWnb/UrvlPcDmyPiropFqyjuHgkl3kUyWvwulxGxG9gu6bw0ay6wiRbpH8VQy2xJp6TXuq++luhfhYH6tQr4erpaYzawv2JopmkkzaMY9rsqIg5VLFoFLJQ0UtI0YDrwTDNri4iXI+LMiJia9pMdFBc67KY1+vcoxYlRJJ1LceHAPhrZu0afxKgY+J9PcSXJ68Dtzdrucer5FMWfty8BL6Sv+RTj1GuA1yjOUI9vgVov5YOrXM5JL/5W4M+kM+gl1XUBsC718FGgu5X6B/wUeAXYAPye4qqC0voHPEgxnt9LET43DtQvihPgv077y8vArJLq20ox3tu3j9xbsf7tqb4twOfLqO+Y5W/ywUnRpvZvgN51An9Iv3/rgTmN7p0/KWpmlomT/qSomVkuHOhmZplwoJuZZcKBbmaWCQe6mVkmHOhmZplwoJuZZcKBbmaWif8DKZ4QEzjE0m4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#after 10 frames\n",
    "for _ in range(10):\n",
    "    new_s,r,done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "plt.imshow(new_s.swapaxes(1,2).reshape(-1,s.shape[-1]).T,vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "agent = MLPClassifier(hidden_layer_sizes=(8,8),   # Weight matrix : (7056, 8) -> (8, 8) -> (8, 6)\n",
    "                      activation='tanh',\n",
    "                      warm_start=True, #keep progress between .fit(...) calls\n",
    "                      max_iter=1 #make only 1 iteration on each .fit(...)\n",
    "                     )\n",
    "#initialize agent to the dimension of state an amount of actions\n",
    "agent.fit([env.reset().flatten()] * n_actions, range(n_actions));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coefs():\n",
    "    layer_1_coef = np.random.rand(7056, 8)\n",
    "    layer_2_coef = np.random.rand(8, 8)\n",
    "    layer_3_coef = np.random.rand(8, 6)\n",
    "    \n",
    "    return [layer_1_coef, layer_2_coef, layer_3_coef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bias():\n",
    "    layer_1_bias = np.random.rand(8)\n",
    "    layer_2_bias = np.random.rand(8)\n",
    "    layer_3_bias = np.random.rand(6)\n",
    "    \n",
    "    return [layer_1_bias, layer_2_bias, layer_3_bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_generated = [generate_coefs() for _ in range(50)]\n",
    "bias_generated = [generate_bias() for _ in range(50)]\n",
    "index_solutions = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifierOverride(MLPClassifier):\n",
    "    def _initialize(self, y, layer_units):\n",
    "        # set all attributes, allocate weights etc for first call\n",
    "        # Initialize parameters\n",
    "        self.n_iter_ = 0\n",
    "        self.t_ = 0\n",
    "        self.n_outputs_ = y.shape[1]\n",
    "\n",
    "        # Compute the number of layers\n",
    "        self.n_layers_ = len(layer_units)\n",
    "\n",
    "        # Output for regression\n",
    "        #if not is_classifier(self):\n",
    "        #    self.out_activation_ = 'identity'\n",
    "        # Output for multi class\n",
    "        if self._label_binarizer.y_type_ == 'multiclass':\n",
    "            self.out_activation_ = 'softmax'\n",
    "        # Output for binary class and multi-label\n",
    "        else:\n",
    "            self.out_activation_ = 'logistic'\n",
    "\n",
    "        # Initialize coefficient and intercept layers\n",
    "        self.coefs_ = coefs_generated[index_solutions]\n",
    "        self.intercepts_ = bias_generated[index_solutions]\n",
    "\n",
    "        for i in range(self.n_layers_ - 1):\n",
    "            coef_init, intercept_init = self._init_coef(layer_units[i],\n",
    "                                                        layer_units[i + 1])\n",
    "            self.coefs_.append(coef_init)\n",
    "            self.intercepts_.append(intercept_init)\n",
    "\n",
    "        #if \"\"\"self.solver in _STOCHASTIC_SOLVERS\"\"\" (True):\n",
    "        self.loss_curve_ = []\n",
    "        self._no_improvement_count = 0\n",
    "        if self.early_stopping:\n",
    "            self.validation_scores_ = []\n",
    "            self.best_validation_score_ = -np.inf\n",
    "        else:\n",
    "            self.best_loss_ = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(t_max = 100):\n",
    "    \"\"\"\n",
    "    plays a game and returns reward and parameters\n",
    "    \"\"\"\n",
    "    s = [env.reset().flatten()]\n",
    "    total_reward = 0\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        \n",
    "        #predict array of action probabilities\n",
    "        probs = agent.predict_proba(s)[0] \n",
    "        \n",
    "        a = np.random.choice(np.asarray(range(n_actions)), p=probs)#<sample action with such probabilities>\n",
    "        \n",
    "        new_s,r,done,info = env.step(a)\n",
    "        new_s = [new_s.flatten()]\n",
    "        #record sessions like you did before\n",
    "        total_reward+=r\n",
    "        \n",
    "        s = new_s\n",
    "        if done: break         \n",
    "    return total_reward, agent.coefs_, agent.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def select_best_n_solutions(samples_returned_number = 2, max_timesteps = 500):\n",
    "    \"\"\" 100 timesteps ~= reward between -1.5 and 1.5)\"\"\"\n",
    "    rewards_list = []\n",
    "    bias_list = []\n",
    "    coefs_list = []\n",
    "    maximas_list = []\n",
    "    returned_coefs = []\n",
    "    returned_bias = []\n",
    "    global index_solutions\n",
    "    \n",
    "    for i in bias_generated:\n",
    "        agent = MLPClassifierOverride(hidden_layer_sizes=(8,8),   # Weight matrix : (7056, 8) -> (8, 8) -> (8, 6)\n",
    "                      activation='tanh',\n",
    "                      warm_start=True, #keep progress between .fit(...) calls\n",
    "                      max_iter=1 #make only 1 iteration on each .fit(...)\n",
    "                     )\n",
    "        \n",
    "        print (\"generating solution number \" + str(index_solutions))\n",
    "        agent.fit([env.reset().flatten()] * n_actions, range(n_actions));\n",
    "        index_solutions += 1\n",
    "        reward, coefs, bias = play_game(max_timesteps)\n",
    "        clear_output()\n",
    "        \n",
    "        rewards_list.append(reward)\n",
    "        coefs_list.append(coefs)\n",
    "        bias_list.append(bias)\n",
    "        print (\"rewards list : \" + str(rewards_list))\n",
    "    \n",
    "    for i in range(samples_returned_number):\n",
    "        maximum_index = rewards_list.index(max(rewards_list)) # getting the index of the best parameters\n",
    "        rewards_list.remove(max(rewards_list))                # removing the best parameter from the rewards_list\n",
    "        maximas_list.append(maximum_index)                   # maximums_list contains the index of the maximas\n",
    "    \n",
    "    for i in maximas_list:\n",
    "        returned_coefs.append(coefs_list[i])\n",
    "        returned_bias.append(bias_list[i])\n",
    "    \n",
    "    print (\"Maximum rewards'index : \" + str(maximas_list))\n",
    "    return returned_coefs, returned_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards list : [-2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, 0.0, -2.0, -2.0, -1.0, -2.0, -2.0, 1.0, -2.0, -2.0, -2.0, -1.0, -2.0, -2.0, -2.0, -2.0, -2.0, -1.0, 1.0, -2.0, -2.0, -2.0, -1.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0]\n",
      "Maximum rewards'index : [18, 28]\n"
     ]
    }
   ],
   "source": [
    "max_generation = 50\n",
    "coefs_generated = [generate_coefs() for _ in range(max_generation)]\n",
    "bias_generated = [generate_bias() for _ in range(max_generation)]\n",
    "index_solutions = 0\n",
    "best_coefs, best_bias = select_best_n_solutions(max_timesteps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def crossover(coefs_computed, bias_computed):\n",
    "    \"\"\"\n",
    "        returns one crossed parameter set out of lists of 2 coefs and bias sets\n",
    "    \"\"\"\n",
    "    if (random() > 0.5):\n",
    "        coefs_computed[0][0], coefs_computed[1][0] = coefs_computed[1][0], coefs_computed[0][0]\n",
    "    if (random() > 0.5):\n",
    "        coefs_computed[0][1], coefs_computed[1][1] = coefs_computed[1][1], coefs_computed[0][1]\n",
    "    if (random() > 0.5):\n",
    "        coefs_computed[0][2], coefs_computed[1][2] = coefs_computed[1][2], coefs_computed[0][2]\n",
    "    if (random() > 0.5):\n",
    "        bias_computed[0][0], bias_computed[1][0] = bias_computed[1][0], bias_computed[0][0]\n",
    "    if (random() > 0.5):\n",
    "        bias_computed[0][1], bias_computed[1][1] = bias_computed[1][1], bias_computed[0][1]\n",
    "    if (random() > 0.5):\n",
    "        bias_computed[0][2], bias_computed[1][2] = bias_computed[1][2], bias_computed[0][2]\n",
    "    \n",
    "    return coefs_computed[0], bias_computed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(coef):\n",
    "    \n",
    "    \"\"\"\n",
    "    returns one mutated set of coefs out of one set of coefs\n",
    "    \"\"\"\n",
    "    \n",
    "    for j in range(7055):\n",
    "        if (random() > 0.995):\n",
    "            coef[0][j] = np.tanh(coef[0][j])\n",
    "    for j in range(7):\n",
    "        if (random() > 0.995):\n",
    "            coef[1][j] = np.tanh(coef[1][j])\n",
    "    for j in range(5):\n",
    "        if (random() > 0.995):\n",
    "            coef[2][j] = np.tanh(coef[2][j])\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_crossed, bias_crossed = [], []\n",
    "\n",
    "for _ in range(max_generation):\n",
    "    tmp_coef, tmp_bia = crossover(best_coefs, best_bias)\n",
    "    coefs_crossed.append(tmp_coef)\n",
    "    bias_crossed.append(tmp_bia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_generation):\n",
    "    coefs_generated[i] = mutation(coefs_crossed[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards list : [-4.0, -4.0, -4.0, -2.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -1.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0]\n",
      "generating solution number 40\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "max_generation = 50\n",
    "coefs_generated = [generate_coefs() for _ in range(max_generation)]\n",
    "bias_generated = [generate_bias() for _ in range(max_generation)]\n",
    "index_solutions = 0\n",
    "\n",
    "for i in range(20):\n",
    "    index_solutions = 0\n",
    "    best_coefs, best_bias = select_best_n_solutions(max_timesteps=200)\n",
    "    \n",
    "    #generating a list of max_generation copies of the best samples:\n",
    "    coefs_generated = []\n",
    "    bias_generated = []\n",
    "    \n",
    "    for i in range(max_generation):\n",
    "        coefs_generated.append(copy.copy(best_coefs[0]))\n",
    "        bias_generated.append(copy.copy(best_bias[0]))\n",
    "        \n",
    "    #generating crossed sets \n",
    "    \"\"\"\n",
    "    for _ in range(max_generation):\n",
    "        tmp_coef, tmp_bia = crossover(best_coefs, best_bias)\n",
    "        coefs_crossed.append(tmp_coef)\n",
    "        bias_crossed.append(tmp_bia)\n",
    "    \"\"\" \n",
    "    #mutating set\n",
    "   # for i in range(max_generation):\n",
    "   #     print i\n",
    "   #     coefs_generated[i] = mutation(coefs_generated[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
